# SOC-Report-Machine-Intelligence-by-Aashish-Tripathy
by Aashish Tripathy 21B080001
We started off with learning python which was easy to adapt to after doing C++. After installing anaconda, we proceeded to Jypiter Notebooks where we learnt creating, editing, executing and about the xheat sheets. Numpy was studied via youtube which taught us Slicing, broadcasting, trigonometric functions, exponent, rational, arithmetic operators etc among a lot else. The Git and Github part of course contained history and branches, setup, commands, workflow, repositories and a lot else. 
https://youtu.be/DVRQoVRzMIY 
https://youtu.be/USjZcfj8yxE
The 3B1B series on Neural Networks helped develop the understanding and visualisation of a neural network and its minute intricacies via gradient dissent plot, backpropagation, calculas and other content with awesome graphics. After this we went on a deep dive in ML via deep learning playlist by Andrew NG where we learnt about Supervised learning with neural networks, binary classification, activation function, gradient descent, Binary Classification on images, Computational graph of NN, NN Notations, Derivatives of Activation Functions, Activation Functions like Sigmoid, ReLU & Leaky ReLU etc.
https://www.youtube.com/watch?v=aircAruvnKk&ab_channel=3Blue1Brown
https://www.youtube.com/watch?v=CS4cs9xVecg&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0
Now in the last week we have reached back propagation, regularisation, early stopping, hyper parameter tuning, softmax, rate decay, Maths in Forward and Backward propagation, Early Stopping, Learning Rate Decay, Hyperparameter Tuning, Batch normalization at test time, Softmax Classification Function, Mini Batch Gradient Descent and choosing its size, Dropout Regularization and why it works, Early Stopping, Vanishing/Exploding Gradients and tackling it via Xavier Weight Initialization etc. We concluded the week with detailed study of convolution and recurrent neural networks and TENSORFLOW.
https://www.youtube.com/playlist?list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO
https://youtu.be/YRhxdVk_sIs
https://youtu.be/LHXXI4-IEns
https://youtu.be/Y2wfIKQyd1I 
https://youtu.be/zfiSAzpy9NM

#### Week 5

This week we started with *Reinforcement Learning* & *Q Learning* and its <br>
implementation in python.<br>
Learnt about various types of RL, Model based & Model free methods. <br>
Learnt about Markov Decision Processes, Temporal Differnces & the *Bellmann* <br>
*Equation*

#### Week 6

We studied about *Open AI Gym Environment* and also implemented Reinforcement <br>
Learning in various Gym environments like *Acrobat v1* and *Frozen Lake* 

#### Week 7

We were intorduced to *Deep Q Networks* <br>
Learnt about Experience Replay & some Action-Selection Policies. <br>

##### Also Started with the Final Poject......Week 8 & 9 


